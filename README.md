# ğŸ“Š SEC Risk Factors RAG Assistant

A **Retrieval-Augmented Generation (RAG)** chatbot that helps users explore and understand **SEC 10-K risk factor disclosures** through natural language conversations.

Built with LangChain, ChromaDB, and Gradio, this application combines semantic search over SEC filings with large language models to provide accurate, context-aware answers about corporate risk factors.

[![Open in Spaces](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg)](https://huggingface.co/spaces/FatimaZh/LawyerChat)

---

## âœ¨ Features

- ğŸ” **Semantic Search** over SEC 10-K risk factor sections
- ğŸ¤– **LLM-Powered Answers** using Retrieval-Augmented Generation
- ğŸ“„ **PDF Upload Support** - Query your own documents alongside SEC data
- ğŸ¯ **Dual-Source Retrieval** - Search both SEC database and uploaded PDFs simultaneously
- ğŸ’¬ **Interactive Chat Interface** built with Gradio
- ğŸ”„ **Automated Dataset Updates** via GitHub Actions
- ğŸ§± **Clean Architecture** - Domain logic separated from UI
- âš¡ **Lightweight Models** - Runs on CPU with 1B parameter LLM
- ğŸ”’ **Privacy-Focused** - All processing happens locally/in-space

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       User Query                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Query Embedding (all-MiniLM-L6-v2)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEC Database    â”‚  â”‚  Uploaded PDF        â”‚
â”‚  (ChromaDB)      â”‚  â”‚  (Temporary Store)   â”‚
â”‚  Persistent      â”‚  â”‚  In-Memory           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Top-K Documents      â”‚
         â”‚  (k=5)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Context Formation    â”‚
         â”‚  + Prompt Template    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LLM Generation       â”‚
         â”‚  (Llama-3.2-1B)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Generated Answer     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

**Data Layer**
- **ChromaDB Vector Store**: Persistent database of pre-processed SEC 10-K risk factors
- **PDF Processing Pipeline**: On-the-fly text extraction, chunking, and indexing

**Model Layer**
- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2` (384-dimensional)
- **LLM**: `unsloth/Llama-3.2-1B-Instruct` (1B parameters, instruction-tuned)

**Processing Layer**
- **RAG Chain**: Retrieval â†’ Context formation â†’ Prompted generation
- **Dual-Source Search**: Parallel queries to SEC database and uploaded PDFs

**Interface Layer**
- **Gradio Blocks UI**: Chat interface with file upload and status indicators

---



## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- 4GB+ RAM (8GB+ recommended)
- (Optional) CUDA-compatible GPU for faster inference

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/FatimaZh/LawyerChat.git
cd LawyerChat
```

2. **Create virtual environment** (recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Run the application**
```bash
python chatbot/app.py
```

The Gradio interface will launch automatically in your browser at `http://localhost:7860`

### First Run Behavior

On first launch, the application will:
1. Download the SEC 10-K vector database from HuggingFace (~100MB)
2. Load the embeddings model (~80MB)
3. Load the LLM model (~2.5GB)

**This may take 5-10 minutes depending on your connection speed.**

Subsequent runs will be faster as models are cached locally.

---

## ğŸ”§ Configuration

All settings are in `config.py`:

### Models

```python
LLM_MODEL = "unsloth/Llama-3.2-1B-Instruct"
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
```

### Generation Parameters

```python
MAX_NEW_TOKENS = 512      # Maximum length of generated answers
TEMPERATURE = 0.7         # Sampling temperature 
TOP_P = 0.9              # Nucleus sampling threshold
RETRIEVAL_K = 5          # Number of documents to retrieve
```

### Device Selection

```python
DEVICE = "cpu"  # or "cuda"
```

---

## ğŸ’¡ Usage Examples

### Basic Queries

Ask questions about SEC risk factors:

```
â“ What are the main cybersecurity risks companies report?
â“ Which companies mention climate change in their risk factors?
â“ What regulatory risks do financial institutions face?
â“ Tell me about supply chain disruption risks
â“ What emerging technology risks are reported?
```

### PDF Upload Workflow

1. Click **"Upload Your PDF"** in the left panel
2. Select a text-based PDF document
3. Wait for processing confirmation
4. Ask questions that combine both sources:
   ```
   â“ How do the risks in my contract compare to SEC filings?
   â“ Does my company's risk disclosure align with industry standards?
   ```

---

## ğŸ§  How It Works

### Retrieval-Augmented Generation (RAG)

Instead of relying solely on the LLM's training data:

1. **Embed Query** â†’ Convert question to 384-dimensional vector
2. **Search Database** â†’ Find semantically similar text chunks (cosine similarity)
3. **Retrieve Top-K** â†’ Get most relevant passages (k=5 or 4+1 for dual-source)
4. **Format Context** â†’ Structure retrieved text for the prompt
5. **Generate Answer** â†’ LLM produces response grounded in retrieved documents

**Benefits**:
- âœ… **Accuracy**: Answers based on actual documents, not hallucinations
- âœ… **Transparency**: Can trace answers back to source filings
- âœ… **Up-to-date**: Database can be refreshed with new filings
- âœ… **Domain-specific**: Focused expertise on SEC risk factors


---

## ğŸ”„ Automated Updates

The system includes automated dataset refreshes via GitHub Actions.

### Workflow: `.github/workflows/daily_updta.yml`

Triggers daily (configurable) to:
1. Fetch latest SEC 10-K filings
2. Extract risk factors using `sec_risk_factors/`
3. Update vector database
4. Push to HuggingFace dataset

---

## ğŸ“Š Technical Details

### Vector Database

- **Backend**: ChromaDB (SQLite + HNSW index)
- **Collection**: `sec_10k_risk_factors`
- **Source**: HuggingFace Dataset `FatimaZh/sec-10k-chroma`
- **Persistence**: Local disk (`./data/chroma_sec/`)

### Text Processing

- **PDF Extraction**: `pdfplumber` 
- **Chunking Strategy**: RecursiveCharacterTextSplitter
  - Chunk size: 1000 characters
  - Overlap: 200 characters
- **Embedding Dimension**: 384

---

## ğŸŒ Deployment

### HuggingFace Spaces

This app is designed to run on HuggingFace Spaces:

1. Create a new Space with **Gradio SDK**
2. Upload all files to the Space
3. Space will auto-deploy

**Important**: On HuggingFace Spaces free tier, the database is re-downloaded on every cold start, which can take several minutes.

### Local Deployment

The application runs on `localhost:7860` by default. To change:

```python
demo.launch(
    server_name="0.0.0.0",  # Allow external connections
    server_port=7860,
    share=True  
)
```

---

## ğŸ› ï¸ Tech Stack

- **Framework**: [LangChain](https://python.langchain.com/) 0.3+
- **UI**: [Gradio](https://gradio.app/) 4.40+
- **LLM**: [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- **Embeddings**: [Sentence-Transformers](https://www.sbert.net/)
- **Vector DB**: [ChromaDB](https://www.trychroma.com/)
- **PDF Processing**: [pdfplumber](https://github.com/jsvine/pdfplumber)


---

## ğŸ“ Example Use Cases

### For Investors
- Compare risk disclosures across companies
- Track emerging risk trends over time
- Due diligence on specific sectors

### For Compliance Teams
- Benchmark your risk disclosures against peers
- Identify common risk language patterns
- Research regulatory risk trends

### For Researchers
- Analyze corporate risk communication
- Study industry-specific risk factors
- Dataset for NLP/finance research

---

## ğŸ“„ License

This project is provided for **educational and research purposes**.

SEC 10-K filings are public domain documents (U.S. government data).

---

## ğŸ‘¥ Authors

### Fatima Zohra  

---

### Khadija Eladnani  



---

<div align="center">

**â­ If you find this project helpful, please consider giving it a star!**

</div>